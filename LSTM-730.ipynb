{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9c3985c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from time import time\n",
    "from statistics import mean\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,.5f}'.format\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# Sklearn tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Neural Networks\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#import pytorch_lightning as pl\n",
    "#from pytorch_lightning import Trainer, seed_everything\n",
    "#from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "# Plotting\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#path of data\n",
    "path = 'energydata_complete.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f80208c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeseriesDataset(Dataset):   \n",
    "    '''\n",
    "    Custom Dataset subclass. \n",
    "    Serves as input to DataLoader to transform X \n",
    "      into sequence data using rolling window. \n",
    "    DataLoader using this dataset will output batches \n",
    "      of `(batch_size, seq_len, n_features)` shape.\n",
    "    Suitable as an input to RNNs. \n",
    "    '''\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray, seq_len: int = 1):\n",
    "        self.X = torch.tensor(X).float()\n",
    "        self.y = torch.tensor(y).float()\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.__len__() - (self.seq_len-1)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.X[index:index+self.seq_len], self.y[index+self.seq_len-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a1848ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_layer_size=100, output_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n",
    "                            torch.zeros(1,1,self.hidden_layer_size))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dab59662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Appliances  lights       T1     RH_1       T2     RH_2       T3     RH_3  \\\n",
      "0          60      30 19.89000 47.59667 19.20000 44.79000 19.79000 44.73000   \n",
      "1          60      30 19.89000 46.69333 19.20000 44.72250 19.79000 44.79000   \n",
      "2          50      30 19.89000 46.30000 19.20000 44.62667 19.79000 44.93333   \n",
      "\n",
      "        T4     RH_4  ...       T9     RH_9   T_out  Press_mm_hg   RH_out  \\\n",
      "0 19.00000 45.56667  ... 17.03333 45.53000 6.60000    733.50000 92.00000   \n",
      "1 19.00000 45.99250  ... 17.06667 45.56000 6.48333    733.60000 92.00000   \n",
      "2 18.92667 45.89000  ... 17.00000 45.50000 6.36667    733.70000 92.00000   \n",
      "\n",
      "   Windspeed  Visibility  Tdewpoint      rv1      rv2  \n",
      "0    7.00000    63.00000    5.30000 13.27543 13.27543  \n",
      "1    6.66667    59.16667    5.20000 18.60619 18.60619  \n",
      "2    6.33333    55.33333    5.10000 28.64267 28.64267  \n",
      "\n",
      "[3 rows x 28 columns]\n",
      "15788\n",
      "15788\n"
     ]
    }
   ],
   "source": [
    "#prepare data\n",
    "df=pd.read_csv(path,parse_dates = ['date']).dropna()\n",
    "df = df.drop(['date'],axis = 1) # 27 features, 1 target\n",
    "print(df.head(3))\n",
    "target = 'Appliances'\n",
    "#print(df.shape)\n",
    "y_df = df[target]\n",
    "x_df = df.loc[:,df.columns != target]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_df, y_df, test_size=0.2, shuffle=False) #  test is 20%\n",
    "\n",
    "#convert all column to float\n",
    "x_train_float = x_train.astype(float)\n",
    "y_train_float = y_train.astype(float)\n",
    "x_test_float = x_test.astype(float)\n",
    "y_test_float = y_test.astype(float)\n",
    "#print(x_train_float.dtypes)\n",
    "\n",
    "#normalized\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_train_normalized = scaler.fit_transform(x_train_float.to_numpy())\n",
    "y_train_normalized = scaler.fit_transform(y_train_float.to_numpy().reshape(-1, 1))\n",
    "print(len(x_train_normalized))\n",
    "print(len(y_train_normalized))\n",
    "#convert to tensors\n",
    "batch_size = 700\n",
    "seq_len=4 #24\n",
    "train_dataset = TimeseriesDataset(x_train_normalized, y_train_normalized, seq_len)\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6b40bc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (lstm): LSTM(108, 100)\n",
      "  (linear): Linear(in_features=100, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#set model\n",
    "\n",
    "model = LSTM(input_size = 27*4)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aec6f5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jfu\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:530: UserWarning: Using a target size (torch.Size([700, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\jfu\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:530: UserWarning: Using a target size (torch.Size([385, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 loss: 0.01615768\n",
      "epoch:   1 loss: 0.01341132\n",
      "epoch:   2 loss: 0.01061046\n",
      "epoch:   3 loss: 0.00987257\n",
      "epoch:   4 loss: 0.00970546\n",
      "epoch:   5 loss: 0.00966647\n",
      "epoch:   6 loss: 0.00963747\n",
      "epoch:   7 loss: 0.00963704\n",
      "epoch:   8 loss: 0.00965812\n",
      "epoch:   9 loss: 0.00969316\n",
      "epoch:  10 loss: 0.00974318\n",
      "epoch:  11 loss: 0.00981009\n",
      "epoch:  12 loss: 0.00989933\n",
      "epoch:  13 loss: 0.01002339\n",
      "epoch:  14 loss: 0.01021134\n",
      "Total average loss: 0.0105158050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(108, 100)\n",
       "  (linear): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "epochs = 15\n",
    "total_loss = []\n",
    "for i in range(epochs):\n",
    "    epoch_loss=[]\n",
    "    for idx, (x,y) in enumerate (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),torch.zeros(1, 1, model.hidden_layer_size))\n",
    "\n",
    "        y_pred = model(x)\n",
    "\n",
    "        single_loss = loss_function(y_pred, y)\n",
    "        epoch_loss.append(single_loss.item())\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "        #epoch_loss.append(single_loss.item())\n",
    "    print(f'epoch: {i:3} loss: {mean(epoch_loss):10.8f}') #10digits,8 digits after decimal\n",
    "    #print(f'current total loss: {total_loss:10.10f}')\n",
    "    total_loss.append(mean(epoch_loss))\n",
    "print(f'Total average loss: {mean(total_loss):10.10f}')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b0170576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Appliances  lights       T1     RH_1       T2     RH_2       T3     RH_3  \\\n",
      "0          60      30 19.89000 47.59667 19.20000 44.79000 19.79000 44.73000   \n",
      "1          60      30 19.89000 46.69333 19.20000 44.72250 19.79000 44.79000   \n",
      "2          50      30 19.89000 46.30000 19.20000 44.62667 19.79000 44.93333   \n",
      "\n",
      "        T4     RH_4  ...       T9     RH_9   T_out  Press_mm_hg   RH_out  \\\n",
      "0 19.00000 45.56667  ... 17.03333 45.53000 6.60000    733.50000 92.00000   \n",
      "1 19.00000 45.99250  ... 17.06667 45.56000 6.48333    733.60000 92.00000   \n",
      "2 18.92667 45.89000  ... 17.00000 45.50000 6.36667    733.70000 92.00000   \n",
      "\n",
      "   Windspeed  Visibility  Tdewpoint      rv1      rv2  \n",
      "0    7.00000    63.00000    5.30000 13.27543 13.27543  \n",
      "1    6.66667    59.16667    5.20000 18.60619 18.60619  \n",
      "2    6.33333    55.33333    5.10000 28.64267 28.64267  \n",
      "\n",
      "[3 rows x 28 columns]\n",
      "batch id0,Test set loss: 0.01288379\n",
      "batch id1,Test set loss: 0.00886956\n",
      "batch id2,Test set loss: 0.01180605\n",
      "batch id3,Test set loss: 0.00670870\n",
      "batch id4,Test set loss: 0.01421091\n",
      "batch id5,Test set loss: 0.02681646\n",
      "====> Test set loss: 0.01354925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jfu\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:530: UserWarning: Using a target size (torch.Size([700, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\jfu\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:530: UserWarning: Using a target size (torch.Size([444, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "#prepare test data\n",
    "#path_test = 'energydata_complete_miss_all.csv'\n",
    "path_test = 'energydata_complete.csv'\n",
    "#df=pd.read_csv(path_test,parse_dates = ['date']).dropna()\n",
    "df=pd.read_csv(path_test).dropna()\n",
    "df = df.iloc[: , 1:]\n",
    "#df = df.drop(['date'],axis = 1) # 27 features, 1 target\n",
    "print(df.head(3))\n",
    "target = 'Appliances'\n",
    "#print(df.shape)\n",
    "y_df = df[target]\n",
    "x_df = df.loc[:,df.columns != target]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_df, y_df, test_size=0.2, shuffle=False) #  test is 20%\n",
    "\n",
    "#convert all column to float\n",
    "#x_train_float = x_train.astype(float)\n",
    "#y_train_float = y_train.astype(float)\n",
    "x_test_float = x_test.astype(float)\n",
    "y_test_float = y_test.astype(float)\n",
    "#print(x_train_float.dtypes)\n",
    "\n",
    "#normalized\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#x_train_normalized = scaler.fit_transform(x_train_float.to_numpy())\n",
    "#y_train_normalized = scaler.fit_transform(y_train_float.to_numpy().reshape(-1, 1))\n",
    "x_test_normalized = scaler.fit_transform(x_test_float.to_numpy())\n",
    "y_test_normalized = scaler.fit_transform(y_test_float.to_numpy().reshape(-1, 1))\n",
    "#print(len(x_train_normalized))\n",
    "#print(len(y_train_normalized))\n",
    "#convert to tensors\n",
    "batch_size = 700\n",
    "seq_len=4 #24\n",
    "test_dataset = TimeseriesDataset(x_test_normalized, y_test_normalized, seq_len)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle = False)\n",
    "test_loss= []\n",
    "with torch.no_grad():\n",
    "    #for data, _ in test_loader:\n",
    "    for batch_idx, (x,y) in enumerate(test_loader):\n",
    "        y_pred = model(x)\n",
    "        single_loss = loss_function(y_pred, y)\n",
    "        test_loss.append(single_loss)\n",
    "        print('batch id'+str(batch_idx)+',Test set loss: {:.8f}'.format(single_loss))\n",
    "test_mean = torch.mean(torch.stack(test_loss))\n",
    "print('====> Test set loss: {:.8f}'.format(test_mean))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51c758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343da0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66c5543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86064284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37de94ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e75d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b512210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
